"""
Q-Method Streamlit Application

Author      : Prof. Dr. Songhee Kang  
Last Update : 2025-07-31  
Description : Likert-based Q-Method survey tool with GitHub push integration
"""
from github import Github
import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import platform
from factor_analyzer import FactorAnalyzer
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import datetime
import networkx as nx
import matplotlib.font_manager as fm

st.set_page_config(page_title="Q-Method Analyzer", layout="wide")
st.title("ë°ì´í„°ì„¼í„° ì§€ì†ê°€ëŠ¥ì„± ì¸ì‹ ì¡°ì‚¬")

DATA_PATH = "responses.csv"
# ì‚¬ì´ë“œë°” ê´€ë¦¬ì ë¡œê·¸ì¸ ì˜ì—­
# -----------------------------
# Secrets (GitHub)
# -----------------------------
def _get_secret(path, default=""):
    try:
        cur = st.secrets
        for key in path.split("."):
            cur = cur[key]
        return cur
    except Exception:
        return default

GH_TOKEN   = _get_secret("github.token")
GH_REPO    = _get_secret("github.repo")
GH_BRANCH  = _get_secret("github.branch", "main")
GH_REMOTEP = _get_secret("github.data_path", DATA_PATH)  # ì›ê²© ì €ì¥ ê²½ë¡œ
GH_README  = _get_secret("github.readme_path", "README.md")         # (ì˜µì…˜)

# -----------------------------
# ì‹¤ì‹œê°„ ì²™ë„ í˜„í™© ê³„ì‚°
# -----------------------------
def calc_scale_counts(answers):
    counts = {i: 0 for i in range(1, 6)}
    for v in answers.values():
        counts[v] += 1
    return counts

def _gh_headers(token):
    return {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
        "Content-Type": "application/json",
        "User-Agent": "streamlit-qmethod-sns"
    }

def gh_get_sha(owner_repo, path, token, branch):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    r = requests.get(url, headers=_gh_headers(token), params={"ref": branch}, timeout=20)
    if r.status_code == 200:
        try:
            return r.json().get("sha")
        except Exception:
            return None
    elif r.status_code == 404:
        return None
    else:
        raise RuntimeError(f"GitHub GET ì‹¤íŒ¨: {r.status_code} {r.text}")

def gh_put_file(owner_repo, path, token, branch, content_bytes, message):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    b64 = base64.b64encode(content_bytes).decode("ascii")
    sha = gh_get_sha(owner_repo, path, token, branch)
    payload = {"message": message, "content": b64, "branch": branch}
    if sha:
        payload["sha"] = sha
    r = requests.put(url, headers=_gh_headers(token), data=json.dumps(payload), timeout=30)
    if r.status_code in (200, 201):
        return True, r.json()
    return False, f"{r.status_code}: {r.text}"

def push_csv_to_github(local_path, remote_path=None, note="Update survey_data.csv"):
    if not (GH_TOKEN and GH_REPO):
        return False, "GitHub secrets ëˆ„ë½(github.token, github.repo)"
    if remote_path is None:
        remote_path = GH_REMOTEP
    try:
        with open(local_path, "rb") as f:
            content = f.read()
    except Exception as e:
        return False, f"ë¡œì»¬ CSV ì½ê¸° ì‹¤íŒ¨: {e}"
    ok, resp = gh_put_file(GH_REPO, remote_path, GH_TOKEN, GH_BRANCH, content, note)
    return ok, resp

# -----------------------------
# ì‚¬ì´ë“œë°” : ì‹¤ì‹œê°„ í˜„í™© íŒ¨ë„
# -----------------------------

with st.sidebar:
    st.subheader("ğŸ” ê´€ë¦¬ì / ë™ê¸°í™”")
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False

    admin_pw = st.sidebar.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ (ì„ íƒ)", type="password")
    if st.sidebar.button("ë¡œê·¸ì¸"):
        if admin_pw and _get_secret("admin.password") == admin_pw:
            st.session_state.authenticated = True
            st.sidebar.success("ì¸ì¦ ì„±ê³µ")
        else:
            st.sidebar.error("ì¸ì¦ ì‹¤íŒ¨")

    auto_sync = st.sidebar.checkbox("ì‘ë‹µ ì €ì¥ ì‹œ GitHub ìë™ í‘¸ì‹œ", value=True)

    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ì²™ë„ í˜„í™©")
    counts = calc_scale_counts(st.session_state['answers'])
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    df_counts = pd.DataFrame({
        "ì²™ë„": [LIKERT[i-1] for i in range(1, 6)],
        "ì„ íƒ ë¬¸í•­ ìˆ˜": [counts[i] for i in range(1, 6)],
        "ìµœëŒ€ í—ˆìš© ê°œìˆ˜": [MAX_COUNT[i] for i in range(1, 6)],
    })

    st.dataframe(df_counts, width="content")

    # Plotly ê·¸ë˜í”„ í‘œì‹œ
    fig = go.Figure(data=[
        go.Bar(name="ì„ íƒ ë¬¸í•­ ìˆ˜", x=LIKERT, y=[counts[i] for i in range(1,6)], marker_color='skyblue'),
        go.Bar(name="ìµœëŒ€ í—ˆìš© ê°œìˆ˜", x=LIKERT, y=[MAX_COUNT[i] for i in range(1,6)], marker_color='salmon')
    ])
    fig.update_layout(
        barmode='group',
        yaxis_title="ë¬¸í•­ ìˆ˜",
        xaxis_tickangle=-20,
        template="plotly_white",
        height=350,
        margin=dict(l=10, r=10, t=30, b=10)
    )
    st.plotly_chart(fig, use_container_width=True)


# -----------------------------
# Utils
# -----------------------------



def is_valid_email(s: str) -> bool:
    if not s: return False
    s = s.strip()
    if len(s) > 150: return False
    return bool(EMAIL_RE.match(s))

def load_csv_safe(path: str):
    if not os.path.exists(path):
        return None
    try:
        if os.path.getsize(path) == 0:
            return None
        df = pd.read_csv(path)
        if df.empty:
            return None
        return df
    except Exception:
        return None

def save_csv_safe(df: pd.DataFrame, path: str):
    try:
        df.to_csv(path, index=False, encoding="utf-8-sig")
        return True
    except Exception as e:
        st.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def ensure_q_columns(df: pd.DataFrame, q_count: int):
    cols = [f"Q{i:02d}" for i in range(1, q_count + 1)]
    for c in cols:
        if c not in df.columns: df[c] = np.nan
    return df, cols

def zscore_rows(a: np.ndarray):
    m = a.mean(axis=1, keepdims=True)
    s = a.std(axis=1, ddof=0, keepdims=True)
    s = np.where(s < EPS, 1.0, s)
    return (a - m) / s

def rank_rows(a: np.ndarray):
    df = pd.DataFrame(a)
    return df.rank(axis=1, method="average", na_option="keep").values

def varimax(Phi, gamma=1.0, q=100, tol=1e-6, seed=42):
    Phi = Phi.copy(); p, k = Phi.shape
    R = np.eye(k); d_old = 0
    for _ in range(q):
        Lambda = Phi @ R
        u, s, vh = np.linalg.svd(
            Phi.T @ (Lambda**3 - (gamma/p) * (Lambda @ np.diag(np.sum(Lambda**2, axis=0))))
        )
        R = u @ vh
        d = np.sum(s)
        if d_old != 0 and d/d_old < 1 + tol: break
        d_old = d
    return Phi @ R, R

def choose_n_factors(eigvals, nmax):
    k = int(np.sum(eigvals >= 1.0))
    return max(2, min(nmax, k))

st.sidebar.subheader("ğŸ” ê´€ë¦¬ì ë¡œê·¸ì¸")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ ë°›ê¸°
if not st.session_state.authenticated:
    input_password = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸ ì…ë ¥", type="password")
    if st.sidebar.button("ë¡œê·¸ì¸"):
        if input_password == st.secrets["admin"]["password"]:
            st.session_state.authenticated = True
            st.sidebar.success("ì¸ì¦ ì„±ê³µ!")
        else:
            st.sidebar.error("ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤.")
if st.session_state.authenticated:
    # ì¸ì¦ëœ ê²½ìš° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
    st.sidebar.success("ê´€ë¦¬ì ëª¨ë“œ í™œì„±í™”ë¨")

    if os.path.exists(DATA_PATH):
        try:
            df_download = pd.read_csv(DATA_PATH)
            st.sidebar.download_button(
                label="ğŸ“¥ ì‘ë‹µ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                data=df_download.to_csv(index=False).encode("utf-8-sig"),
                file_name="responses.csv",
                mime="text/csv"
            )
        except pd.errors.EmptyDataError:
            st.sidebar.warning("âš ï¸ ì €ì¥ëœ ì‘ë‹µ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.sidebar.info("â„¹ï¸ ì•„ì§ ì €ì¥ëœ ì‘ë‹µ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
def get_korean_fontprop():
    font_path = "fonts/NanumGothic.ttf"
    if os.path.exists(font_path):
        return fm.FontProperties(fname=font_path)
    else:
        return fm.FontProperties()  # fallback
font_prop = get_korean_fontprop()

def push_to_github(local_file_path):
    g = Github(st.secrets["github"]["token"])
    repo = g.get_repo(st.secrets["github"]["repo"])
    path_in_repo = st.secrets["github"]["path"]

    # í˜„ì¬ íŒŒì¼ì„ ì½ê³  base64ë¡œ ì¸ì½”ë”©
    with open(local_file_path, "rb") as file:
        content = file.read()

    try:
        # ê¸°ì¡´ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (SHA í•„ìš”)
        contents = repo.get_contents(path_in_repo)
        repo.update_file(
            path=path_in_repo,
            message=f"Update response.csv at {datetime.datetime.now().isoformat()}",
            content=content,
            sha=contents.sha
        )
    except Exception:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        repo.create_file(
            path=path_in_repo,
            message=f"Create response.csv at {datetime.datetime.now().isoformat()}",
            content=content
        )

with st.expander("ğŸ“˜ ì¡°ì‚¬ ê°œìš”", expanded=True):
    st.markdown("""
    ë³¸ ì¡°ì‚¬ëŠ” ë°ì´í„°ì„¼í„°ì˜ ê¸°ìˆ Â·ì…ì§€Â·ì‚¬ëŒÂ·ê±°ë²„ë„ŒìŠ¤ì— ëŒ€í•œ ì‚¬íšŒì  ìˆ˜ìš©ì„±ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì§„ìˆ ë¬¸ì— ëŒ€í•´, ê·€í•˜ì˜ ì¸ì‹ì„ íŒŒì•…í•˜ê³ ì í•©ë‹ˆë‹¤.<br>
    í•œêµ­ê³µí•™ëŒ€í•™êµ ì£¼ê´€ í•™ìˆ  ì—°êµ¬ ëª©ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ëŠ” ë³¸ ì¡°ì‚¬ëŠ” ì¡°ì‚¬ì§€ ìì²´ì˜ ìµëª…ì„±ì´ ìœ ì§€ë˜ë©° ì‘ë‹µì ê³ ìœ ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì´ë©”ì¼ì„ ìˆ˜ì§‘ í›„ íŒŒê¸°í•©ë‹ˆë‹¤.<br>
    ëª¨ë“  ì„¹ì…˜ì— ì°¸ì—¬í•˜ì‹œëŠ” ë° 10ë¶„ ì´ë‚´ë¡œ ì†Œìš”ë©ë‹ˆë‹¤.<br>
    <br>
    ë°ì´í„°ì„¼í„°ëŠ” ì¸ê³µì§€ëŠ¥, í´ë¼ìš°ë“œ, ë””ì§€í„¸ ì‚°ì—… ë°œì „ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ê¸°ë°˜ ì‹œì„¤ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¸ì™€ ë™ì‹œì— ë§‰ëŒ€í•œ ì „ë ¥ì„ ì†Œë¹„í•˜ê³ , ë¬¼ì„ ë§ì´ ì‚¬ìš©í•˜ë©°, ì…ì§€ ì„ ì • ê³¼ì •ì—ì„œ ì‹œë¯¼ë“¤ê³¼ ê°ˆë“±ì„ ë¹šê¸°ë„ í•©ë‹ˆë‹¤.<br>
    <br>
    ë™ ì—°êµ¬ì—ì„œëŠ”<br>
    - ì‹œë¯¼ë“¤ì€ ë°ì´í„°ì„¼í„°ì— ëŒ€í•´ ì–´ë–¤ ìƒê°ì„ ê°€ì§€ê³  ìˆì„ê¹Œ?<br>
    - ê·¸ë¦¬ê³  ê·¸ íŒë‹¨ì€ ì–´ë–¤ ê°€ì¹˜ë‚˜ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë‹¬ë¼ì§ˆê¹Œ?<br>
    ë¥¼ ì•Œì•„ë³´ê¸° ìœ„í•œ ëª©ì ì„ ê°€ì§€ê³  ì„¤ë¬¸ì¡°ì‚¬ë¥¼ ì‹œí–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.<br><br>
    ì„¤ë¬¸ì€ ì´ 24ê°œì˜ ë¬¸ì¥ì„ ì œì‹œí•˜ë©°, ì´ ë¬¸ì¥ë“¤ì€ ì‚¬ëŒë“¤ì´ ë°ì´í„°ì„¼í„°ì— ëŒ€í•´ í”íˆ í•˜ëŠ” ì£¼ì¥ì´ë‚˜ ì˜ê²¬ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.
""", unsafe_allow_html=True)
with st.expander("ğŸ§© ì„¹ì…˜ ì„¤ëª…", expanded=True):
    st.markdown("""
    ì„¤ë¬¸ì€ ë¦¬ì»¤íŠ¸ ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë˜ë©°, ì œì‹œëœ 24ê°œ ë¬¸ì¥ì„ â€œë‚˜ëŠ” ì´ ìƒê°ì— ì–¼ë§ˆë‚˜ ë™ì˜í•˜ëŠ”ê°€?â€ì˜ ê¸°ì¤€ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.<br>
    <b>ë§¤ìš° ë™ì˜í•˜ê±°ë‚˜ ë™ì˜í•˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ì´ 1-3ë¬¸ì¥ ì´ë‚´ë¡œ í•˜ì‹œê³ , ê¸°ë³¸ì ìœ¼ë¡œ ì¤‘ë¦½ì ì´ê±°ë‚˜ íŒë‹¨ì„ ìœ ë³´í•˜ì‹œê³  ì‹¶ì€ ë¬¸ì¥ì€ ì£¼ë¡œ ë³´í†µì´ë‹¤ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.</b><br>
    ë¬¸ì¥ë“¤ì€ ë‹¤ìŒ ë„¤ ê°œì˜ ê´€ì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:<br>
      1) ê¸°ìˆ (Technology): ì´ ì˜ì—­ì€ ë°ì´í„°ì„¼í„°ê°€ ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ëŠ”ì§€ë¥¼ ì‹œë¯¼ë“¤ì´ ì–´ë–»ê²Œ ë°”ë¼ë³´ëŠ”ì§€ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì¬ìƒì—ë„ˆì§€ ì‚¬ìš© ì—¬ë¶€, ì¹œí™˜ê²½ ëƒ‰ê° ê¸°ìˆ , ë°±ì—… ì „ë ¥ ë°©ì‹, ê¸°ìˆ ì˜ ì•ˆì „ì„±ê³¼ ê±°ë¦¬ê° ë“±ì´ ì—¬ê¸°ì— í¬í•¨ë©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ê¸°ìˆ ì˜ ì¢…ë¥˜ë‚˜ ë°©ì‹ì´ ì‹œë¯¼ì˜ ì‹ ë¢°ë‚˜ ìˆ˜ìš©ì„±ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?<br>
      2) ì‚¬ëŒ (People): ì´ ì˜ì—­ì€ ë°ì´í„°ì„¼í„°ë¥¼ ë‘˜ëŸ¬ì‹¼ ì‚¬ëŒë“¤ ê°„ì˜ ê´€ê³„ì™€ ì‹ ë¢°, ì°¸ì—¬ì˜ ë°©ì‹ì— ê´€í•œ ì‹œë¯¼ë“¤ì˜ ì¸ì‹ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì‹œë¯¼ ì˜ê²¬ì´ ë°˜ì˜ë˜ì—ˆëŠ”ì§€, ì„¤ëª…íšŒê°€ í˜•ì‹ì ì´ì§€ ì•Šì•˜ëŠ”ì§€, ì •ë¶€ì™€ ê¸°ì—… ì¤‘ ëˆ„ê°€ ë” ì‹ ë¢°ë°›ëŠ”ì§€ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ë°ì´í„°ì„¼í„°ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìë“¤ ì‚¬ì´ì˜ ì‹ ë¢°ì™€ ê´€ê³„ê°€, ì‹œë¯¼ë“¤ì˜ ìˆ˜ìš©ì„± íŒë‹¨ì— ì–´ë–¤ ì˜í–¥ì„ ì¤€ë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?<br>
      3) ì¥ì†Œ (Place): ì´ ì˜ì—­ì€ ë°ì´í„°ì„¼í„°ê°€ ì–´ë””ì— ë“¤ì–´ì„œëŠëƒì— ë”°ë¼ ì‹œë¯¼ë“¤ì´ ì–´ë–»ê²Œ ë°˜ì‘í•˜ëŠ”ì§€ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ê¸°ì¡´ ì‚°ì—… ë¶€ì§€ì˜ í™œìš©, ì§€ì—­ ì •ì²´ì„±ê³¼ì˜ ì¡°í™”, ìì—°í™˜ê²½ í›¼ì†, ìˆ˜ë„ê¶Œ/ì§€ë°© ì°¨ì´, ì™¸ë¶€ ìë³¸ ì£¼ë„ì˜ ë¶ˆì‹  ê°€ëŠ¥ì„± ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì…ì§€ì˜ íŠ¹ì„±ê³¼ ë§¥ë½ì´ ì‹œë¯¼ ìˆ˜ìš©ì„±ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?<br>
      4) ê³¼ì • (Process): ì´ ì˜ì—­ì€ ë°ì´í„°ì„¼í„°ê°€ ì–´ë–¤ ì ˆì°¨ì™€ ë°©ì‹ìœ¼ë¡œ ê²°ì •Â·ìš´ì˜ë˜ì—ˆëŠ”ì§€ë¥¼ ì‹œë¯¼ë“¤ì´ ì–´ë–»ê²Œ í‰ê°€í•˜ëŠ”ì§€ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì •ë³´ ê³µê°œ ì‹œì , í™˜ê²½ì˜í–¥í‰ê°€ì˜ ì‹ ë¢°ë„, ê¸°ì—…â€“ì§€ìì²´ í˜‘ë ¥ ì—¬ë¶€, ì‚¬í›„ ëª¨ë‹ˆí„°ë§ì˜ ìœ ë¬´ ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ê²°ì • ê³¼ì •ì˜ íˆ¬ëª…ì„±ê³¼ ì°¸ì—¬ ë°©ì‹ì´ ì‹œë¯¼ì˜ ì‹ ë¢°ì™€ ìˆ˜ìš©ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?<br>
    """, unsafe_allow_html=True)

tab1, tab2, tab3 = st.tabs(["âœï¸ ì„¤ë¬¸ ì‘ë‹µ",  "ğŸ“Š", "ğŸ§ "])


statements = [
    "ë°ì´í„°ì„¼í„°ëŠ” ì¬ìƒì—ë„ˆì§€ë¥¼ ì‚¬ìš©í•  ë•Œ í™˜ê²½ ì±…ì„ì„±ì„ ê°–ì¶˜ ì‹œì„¤ë¡œ í‰ê°€ë°›ì„ ìˆ˜ ìˆë‹¤.",
    "ë””ì ¤ì´ë‚˜ ê°€ìŠ¤ ë°œì „ê¸°ë¥¼ ë°±ì—… ì „ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ê²½ìš° í™˜ê²½ì  ìš°ë ¤ê°€ ì œê¸°ë  ìˆ˜ ìˆë‹¤.",
    "ë¬¼ ì ˆì•½ì´ë‚˜ ì¹œí™˜ê²½ ëƒ‰ê° ê¸°ìˆ ì˜ ë„ì…ì€ ì‹œë¯¼ ì‹ ë¢°ì— ê¸ì •ì  ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤.",
    "ê¸°ìˆ ì´ ìµœì‹ ì´ë”ë¼ë„ ì•ˆì „ì„± í™•ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì‹œë¯¼ ë¶ˆì•ˆì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.",
    "ë°ì´í„°ì„¼í„° ê¸°ìˆ ì€ ë¹„ìš© íš¨ìœ¨ì„±ë³´ë‹¤ëŠ” ì‚¬íšŒì  ì±…ì„ì„ ìš°ì„ ì‹œí•´ì•¼ í•œë‹¤ëŠ” ê²¬í•´ê°€ ìˆë‹¤.",
    "ê¸°ìˆ ì´ ë‚¯ì„¤ê±°ë‚˜ ë³µì¡í•˜ê²Œ ì¸ì‹ë˜ë©´ ì‹œë¯¼ê³¼ì˜ ê±°ë¦¬ê°ì´ ì»¤ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ë°ì´í„°ì„¼í„° ê±´ì„¤ ê³¼ì •ì— ì‹œë¯¼ ì˜ê²¬ì´ ë°˜ì˜ë˜ì§€ ì•Šìœ¼ë©´ ë°˜ë°œ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ ì‚¬íšŒì™€ ì¥ê¸°ì  ê´€ê³„ë¥¼ ë§ºì–´ì˜¨ ê¸°ì—…ì€ ë” ë†’ì€ ì‹ ë¢°ë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤.",
    "ì„¤ëª…íšŒê°€ í˜•ì‹ì ìœ¼ë¡œ ë³´ì¼ ê²½ìš°, ì‹œë¯¼ ë¶ˆì‹ ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.",
    "ì •ë³´ ì ‘ê·¼ì„±ì´ ë‚®ì„ìˆ˜ë¡ ì‹œë¯¼ì˜ ë¶ˆì•ˆê³¼ ì˜ì‹¬ì´ ì¦ê°€í•  ìˆ˜ ìˆë‹¤.",
    "ê°ˆë“± ìƒí™©ì—ì„œëŠ” ì¤‘ë¦½ì  ì œ3ìì˜ ê°œì…ì´ ì¡°ì •ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.",
    "ë™ì¼í•œ ì„¤ëª…ì´ë¼ë„ ì •ë¶€ê°€ ì „ë‹¬í•  ê²½ìš° ê¸°ì—…ë³´ë‹¤ ë” ì‹ ë¢°ë°›ì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.",
    "ê¸°ì¡´ ê³µì¥ì´ë‚˜ ë°œì „ì†Œ ë¶€ì§€ë¥¼ ì¬í™œìš©í•œ ë°ì´í„°ì„¼í„°ëŠ” ìˆ˜ìš©ì„±ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ ì •ì²´ì„±ê³¼ ì¡°í™”ë¥¼ ì´ë£¨ì§€ ëª»í•˜ëŠ” ì…ì§€ëŠ” ê±°ë¶€ê°ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.",
    "ìì—°ê²½ê´€ í›¼ì†ì´ ë°œìƒí•˜ëŠ” ê²½ìš°, ê¸°ìˆ  ìš°ìˆ˜ì„±ë§Œìœ¼ë¡œ ìˆ˜ìš©ì„± í™•ë³´ëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤.",
    "ìˆ˜ë„ê¶Œê³¼ ì§€ë°©ì€ ë°ì´í„°ì„¼í„° ì…ì§€ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ê¸°ì¤€ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì™¸ë¶€ ìë³¸ ì£¼ë„ì˜ ì¼ë°©ì ì¸ ì…ì§€ ê²°ì •ì€ ì§€ì—­ì‚¬íšŒì˜ ì‹ ë¢°ë¥¼ ì €í•´í•  ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ì— ì‹¤ì§ˆì ì¸ í˜œíƒì´ ì œê³µë˜ë©´ ì‹œë¯¼ ìˆ˜ìš©ì„±ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì •ë³´ê°€ íˆ¬ëª…í•˜ê²Œ ê³µê°œë˜ë©´ ì‹œë¯¼ ì‹ ë¢°ê°€ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "í™˜ê²½ì˜í–¥í‰ê°€ ê²°ê³¼ëŠ” ì‹œë¯¼ë“¤ì˜ ìˆ˜ìš© ì—¬ë¶€ì— ì¤‘ìš”í•œ íŒë‹¨ ê¸°ì¤€ì´ ë  ìˆ˜ ìˆë‹¤.",
    "ê¸°ì—…ê³¼ ì§€ìì²´ê°€ ê³µë™ìœ¼ë¡œ ê²°ì •í•œ í”„ë¡œì íŠ¸ëŠ” ë” ë†’ì€ ì‹ ë¢°ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.",
    "ë²•ì  ìš”ê±´ì„ ì¶©ì¡±í•˜ë”ë¼ë„ ì‹œë¯¼ ì‹ ë¢°ë¥¼ í™•ë³´í•˜ë ¤ë©´ ì¶”ê°€ì ì¸ ì„¤ëª…ì´ í•„ìš”í•  ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ ì–¸ë¡ ì´ ì‹ ì†í•˜ê³  ì •í™•í•˜ê²Œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ë©´ ì‹ ë¢°ì„± ì œê³ ì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤.",
    "ë°ì´í„°ì„¼í„° ì™„ê³µ ì´í›„ì—ë„ ëª¨ë‹ˆí„°ë§ê³¼ í”¼ë“œë°± ì²´ê³„ê°€ ì§€ì†ë˜ë©´ ì‹ ë¢° ìœ ì§€ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤."
]

section_map = {
    "Technology": range(0, 6),
    "People": range(6, 12),
    "Place": range(12, 18),
    "Process": range(18, 24)
}

scale_map = {
    "ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ": 1,
    "ë™ì˜í•˜ì§€ ì•ŠìŒ": 2,
    "ë³´í†µì´ë‹¤": 3,
    "ë™ì˜í•¨": 4,
    "ë§¤ìš° ë™ì˜í•¨": 5
}
scale_labels = list(scale_map.keys())

with tab1:
    st.subheader("âœï¸ ì„¤ë¬¸ì— ì‘ë‹µí•´ ì£¼ì„¸ìš”")
    responses = {}

    with st.form(key="likert_form"):
        email = st.text_input("ì´ë©”ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš” (í•„ìˆ˜ ì‚¬í•­)", key="email_input")

        for idx, stmt in enumerate(statements, 1):
            response = st.radio(
                f"{idx}. {stmt}", options=scale_labels, key=f"stmt_{idx}", horizontal=True
            )
            responses[f"Q{idx:02}"] = scale_map[response]

        # ì´ë©”ì¼ë„ ì‘ë‹µì— ì¶”ê°€
        responses["email"] = email.strip()

        submitted = st.form_submit_button("ì œì¶œí•˜ê¸°")

    if submitted:
        df_new = pd.DataFrame([responses])
        if os.path.exists(DATA_PATH):
            df_old = pd.read_csv(DATA_PATH)
            df_all = pd.concat([df_old, df_new], ignore_index=True)
        else:
            df_all = df_new
        df_all.to_csv(DATA_PATH, index=False)
        st.success("ì‘ë‹µì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        push_to_github(DATA_PATH)

with tab2:
    if os.path.exists(DATA_PATH):

        df = pd.read_csv(DATA_PATH)
        st.subheader("ğŸ“ˆ ìœ í˜• ë¶„ì„ ë° TPPP ì˜ì—­ë³„ í”„ë¡œíŒŒì¼ë§")
        if len(df) >= 5:
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
            df_numeric = df.select_dtypes(include=[np.number])

            # ë™ì¼í•œ shapeì˜ ë…¸ì´ì¦ˆ ìƒì„± í›„ ë”í•˜ê¸°
            noise = np.random.normal(0, 0.001, df_numeric.shape)
            df_noise = df_numeric + noise

            # â–¶ï¸ ê³ ìœ ê°’ ê¸°ë°˜ìœ¼ë¡œ factor ìˆ˜ ìë™ ê²°ì •
            fa_temp = FactorAnalyzer(rotation=None)
            fa_temp.fit(df_noise)
            eigen_values, _ = fa_temp.get_eigenvalues()
            n_factors = sum(eigen_values >= 1.0)

            st.info(f"ğŸ” ê³ ìœ ê°’ 1.0 ì´ìƒ ê¸°ì¤€, ì¶”ì¶œëœ ìš”ì¸ ìˆ˜: {n_factors}ê°œ")

            # â–¶ï¸ ì‹¤ì œ ë¶„ì„
            fa = FactorAnalyzer(n_factors=n_factors, rotation='varimax')
            fa.fit(df_noise)

            # â–¶ï¸ ìš”ì¸ ë¶€í•˜ í–‰ë ¬ ìƒì„±
            loadings = pd.DataFrame(
                fa.loadings_,
                index=[f"Q{idx+1}" for idx in range(df_numeric.shape[1])],
                columns=[f"Type{i+1}" for i in range(n_factors)]
            )

            st.write("ğŸ“Œ ìœ í˜• ë¶€í•˜ í–‰ë ¬:")
            st.dataframe(loadings)

            # â–¶ï¸ TPPP ì˜ì—­ë³„ í”„ë¡œíŒŒì¼ ìš”ì•½
            st.write("ğŸ“Š ìœ í˜•ë³„ TPPP í‰ê·  í”„ë¡œíŒŒì¼")
            result = []
            for factor in loadings.columns:
                scores = []
                for sec, idxs in section_map.items():
                    mean = loadings.loc[[f"Q{i+1}" for i in idxs], factor].mean()
                    scores.append((sec, mean))
                row = pd.DataFrame(dict(scores), index=[factor])
                result.append(row)
            summary = pd.concat(result)
            st.dataframe(summary.style.background_gradient(axis=1, cmap='Blues'))

            fig, ax = plt.subplots()
            summary.T.plot(kind='bar', ax=ax)
            ax.set_title("ìœ í˜•ë³„ TPPP ì˜ì—­ ì ìˆ˜", fontproperties=font_prop)
            st.pyplot(fig)
        else:
            st.warning("ìµœì†Œ 5ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")

with tab3:
    if os.path.exists(DATA_PATH):
        df = pd.read_csv(DATA_PATH)
        st.subheader("ğŸ§  TPPP ì¸ì§€ íë¦„ ë° í”¼ë“œë°± êµ¬ì¡° ìš”ì•½")

        if len(df) >= 5:
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
            df_numeric = df.select_dtypes(include=[np.number])
            
            # ë™ì¼í•œ shapeì˜ ë…¸ì´ì¦ˆ ìƒì„± í›„ ë”í•˜ê¸°
            noise = np.random.normal(0, 0.001, df_numeric.shape)
            df = df_numeric + noise
            
            # ìƒê´€í–‰ë ¬ ê³„ì‚°
            corr = df.corr()
            tp_labels = list(section_map.keys())
            block_corr = pd.DataFrame(index=tp_labels, columns=tp_labels, dtype=float)

            for sec1, idxs1 in section_map.items():
                for sec2, idxs2 in section_map.items():
                    sub_corrs = [corr.iloc[i, j] for i in idxs1 for j in idxs2 if i != j]
                    block_corr.loc[sec1, sec2] = np.mean(sub_corrs)

            # DiGraph ë°©í–¥ì„± ë¶€ì—¬ (ê°•í•œ ë°©í–¥ ê¸°ì¤€)
            DG = nx.DiGraph()
            for i in tp_labels:
                DG.add_node(i)

            for i in tp_labels:
                for j in tp_labels:
                    if i != j:
                        weight_ij = block_corr.loc[i, j]
                        weight_ji = block_corr.loc[j, i]
                        if weight_ij > weight_ji and weight_ij > 0.4:
                            DG.add_edge(i, j, weight=round(weight_ij, 2))

            st.markdown("### ğŸ”„ TPPP ì¸ì§€ íë¦„ ë°©í–¥ ê·¸ë˜í”„ (DiGraph)")
            pos = nx.circular_layout(DG)
            plt.figure(figsize=(6, 6))
            nx.draw_networkx_nodes(DG, pos, node_color='skyblue', node_size=2000)
            nx.draw_networkx_labels(DG, pos, font_size=12, font_family=font_prop.get_name())
            nx.draw_networkx_edges(DG, pos, width=2, arrows=True, arrowstyle='-|>')
            edge_labels = {(u, v): f"{d['weight']}" for u, v, d in DG.edges(data=True)}
            nx.draw_networkx_edge_labels(DG, pos, edge_labels=edge_labels, font_size=10, font_family=font_prop.get_name())
            plt.title("TPPP ì˜ì—­ ê°„ ì¸ì§€ íë¦„ êµ¬ì¡° (DiGraph)", fontproperties=font_prop)
            st.pyplot(plt)

            # ë£¨í”„ íƒì§€
            st.markdown("### ğŸ” í”¼ë“œë°± ë£¨í”„ êµ¬ì¡° ê°ì§€ ê²°ê³¼")
            cycles = [cycle for cycle in nx.simple_cycles(DG) if len(cycle) >= 3]

            if cycles:
                for i, loop in enumerate(cycles, 1):
                    st.markdown(f"- ë£¨í”„ {i}: {' â†’ '.join(loop)} â†’ {loop[0]}")
            else:
                st.info("ë£¨í”„(ìê¸°ê°•í™” í”¼ë“œë°± êµ¬ì¡°)ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            # íˆíŠ¸ë§µ ì¶œë ¥
            st.markdown("### ğŸ“Š TPPP ìƒê´€ í–‰ë ¬ íˆíŠ¸ë§µ")
            fig2, ax2 = plt.subplots()
            sns.heatmap(block_corr.astype(float), annot=True, cmap='coolwarm', vmin=-1, vmax=1,
                        fmt=".2f", linewidths=0.5, ax=ax2, cbar=True)
            ax2.set_title("TPPP ë¸”ë¡ ê°„ ìƒê´€ íˆíŠ¸ë§µ", fontproperties=font_prop)
            ax2.set_xticklabels(ax2.get_xticklabels(), fontproperties=font_prop)
            ax2.set_yticklabels(ax2.get_yticklabels(), fontproperties=font_prop)
            st.pyplot(fig2)
        else:
            st.warning("ìµœì†Œ 5ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

