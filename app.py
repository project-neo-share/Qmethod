"""
Q-Method Streamlit Application

Author      : Prof. Dr. Songhee Kang  
Last Update : 2025-12-08  
Description : Likert-based Q-Method survey tool with GitHub push integration
"""

from github import Github
import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import platform
from factor_analyzer import FactorAnalyzer
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import datetime
import networkx as nx
import matplotlib.font_manager as fm

import requests
import base64
import json
import re
import plotly.graph_objects as go

# ---------------------------------
# ê¸°ë³¸ ì„¤ì •
# ---------------------------------
st.set_page_config(page_title="Q-Method Analyzer", layout="wide")
st.title("ë°ì´í„°ì„¼í„° ì§€ì†ê°€ëŠ¥ì„± ì¸ì‹ ì¡°ì‚¬")

DATA_PATH = "responses.csv"
EPS = 1e-8
EMAIL_RE = re.compile(r"^[^@\s]+@[^@\s]+\.[^@\s]+$")

# Likert ìŠ¤ì¼€ì¼ ë° í—ˆìš© ê°œìˆ˜ (24ë¬¸í•­ ê¸°ì¤€ Q-sortí˜• ë¶„í¬ ì˜ˆì‹œ: 2 + 5 + 10 + 5 + 2 = 24)
LIKERT = ["ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ", "ë™ì˜í•˜ì§€ ì•ŠìŒ", "ë³´í†µì´ë‹¤", "ë™ì˜í•¨", "ë§¤ìš° ë™ì˜í•¨"]
MAX_COUNT = {
    1: 2,   # ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ
    2: 5,   # ë™ì˜í•˜ì§€ ì•ŠìŒ
    3: 10,  # ë³´í†µì´ë‹¤
    4: 5,   # ë™ì˜í•¨
    5: 2    # ë§¤ìš° ë™ì˜í•¨
}

# ---------------------------------
# ë¬¸í•­ ì •ì˜ / TPPP ë§¤í•‘
# ---------------------------------
statements = [
    "ë°ì´í„°ì„¼í„°ëŠ” ì¬ìƒì—ë„ˆì§€ë¥¼ ì‚¬ìš©í•  ë•Œ í™˜ê²½ ì±…ì„ì„±ì„ ê°–ì¶˜ ì‹œì„¤ë¡œ í‰ê°€ë°›ì„ ìˆ˜ ìˆë‹¤.",
    "ë””ì ¤ì´ë‚˜ ê°€ìŠ¤ ë°œì „ê¸°ë¥¼ ë°±ì—… ì „ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ê²½ìš° í™˜ê²½ì  ìš°ë ¤ê°€ ì œê¸°ë  ìˆ˜ ìˆë‹¤.",
    "ë¬¼ ì ˆì•½ì´ë‚˜ ì¹œí™˜ê²½ ëƒ‰ê° ê¸°ìˆ ì˜ ë„ì…ì€ ì‹œë¯¼ ì‹ ë¢°ì— ê¸ì •ì  ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆë‹¤.",
    "ê¸°ìˆ ì´ ìµœì‹ ì´ë”ë¼ë„ ì•ˆì „ì„± í™•ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì‹œë¯¼ ë¶ˆì•ˆì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.",
    "ë°ì´í„°ì„¼í„° ê¸°ìˆ ì€ ë¹„ìš© íš¨ìœ¨ì„±ë³´ë‹¤ëŠ” ì‚¬íšŒì  ì±…ì„ì„ ìš°ì„ ì‹œí•´ì•¼ í•œë‹¤ëŠ” ê²¬í•´ê°€ ìˆë‹¤.",
    "ê¸°ìˆ ì´ ë‚¯ì„¤ê±°ë‚˜ ë³µì¡í•˜ê²Œ ì¸ì‹ë˜ë©´ ì‹œë¯¼ê³¼ì˜ ê±°ë¦¬ê°ì´ ì»¤ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ë°ì´í„°ì„¼í„° ê±´ì„¤ ê³¼ì •ì— ì‹œë¯¼ ì˜ê²¬ì´ ë°˜ì˜ë˜ì§€ ì•Šìœ¼ë©´ ë°˜ë°œ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ ì‚¬íšŒì™€ ì¥ê¸°ì  ê´€ê³„ë¥¼ ë§ºì–´ì˜¨ ê¸°ì—…ì€ ë” ë†’ì€ ì‹ ë¢°ë¥¼ ë°›ì„ ìˆ˜ ìˆë‹¤.",
    "ì„¤ëª…íšŒê°€ í˜•ì‹ì ìœ¼ë¡œ ë³´ì¼ ê²½ìš°, ì‹œë¯¼ ë¶ˆì‹ ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.",
    "ì •ë³´ ì ‘ê·¼ì„±ì´ ë‚®ì„ìˆ˜ë¡ ì‹œë¯¼ì˜ ë¶ˆì•ˆê³¼ ì˜ì‹¬ì´ ì¦ê°€í•  ìˆ˜ ìˆë‹¤.",
    "ê°ˆë“± ìƒí™©ì—ì„œëŠ” ì¤‘ë¦½ì  ì œ3ìì˜ ê°œì…ì´ ì¡°ì •ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.",
    "ë™ì¼í•œ ì„¤ëª…ì´ë¼ë„ ì •ë¶€ê°€ ì „ë‹¬í•  ê²½ìš° ê¸°ì—…ë³´ë‹¤ ë” ì‹ ë¢°ë°›ì„ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.",
    "ê¸°ì¡´ ê³µì¥ì´ë‚˜ ë°œì „ì†Œ ë¶€ì§€ë¥¼ ì¬í™œìš©í•œ ë°ì´í„°ì„¼í„°ëŠ” ìˆ˜ìš©ì„±ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ ì •ì²´ì„±ê³¼ ì¡°í™”ë¥¼ ì´ë£¨ì§€ ëª»í•˜ëŠ” ì…ì§€ëŠ” ê±°ë¶€ê°ì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤.",
    "ìì—°ê²½ê´€ í›¼ì†ì´ ë°œìƒí•˜ëŠ” ê²½ìš°, ê¸°ìˆ  ìš°ìˆ˜ì„±ë§Œìœ¼ë¡œ ìˆ˜ìš©ì„± í™•ë³´ëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤.",
    "ìˆ˜ë„ê¶Œê³¼ ì§€ë°©ì€ ë°ì´í„°ì„¼í„° ì…ì§€ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ê¸°ì¤€ì„ ê°€ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì™¸ë¶€ ìë³¸ ì£¼ë„ì˜ ì¼ë°©ì ì¸ ì…ì§€ ê²°ì •ì€ ì§€ì—­ì‚¬íšŒì˜ ì‹ ë¢°ë¥¼ ì €í•´í•  ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ì— ì‹¤ì§ˆì ì¸ í˜œíƒì´ ì œê³µë˜ë©´ ì‹œë¯¼ ìˆ˜ìš©ì„±ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "ì´ˆê¸° ë‹¨ê³„ì—ì„œ ì •ë³´ê°€ íˆ¬ëª…í•˜ê²Œ ê³µê°œë˜ë©´ ì‹œë¯¼ ì‹ ë¢°ê°€ ë†’ì•„ì§ˆ ìˆ˜ ìˆë‹¤.",
    "í™˜ê²½ì˜í–¥í‰ê°€ ê²°ê³¼ëŠ” ì‹œë¯¼ë“¤ì˜ ìˆ˜ìš© ì—¬ë¶€ì— ì¤‘ìš”í•œ íŒë‹¨ ê¸°ì¤€ì´ ë  ìˆ˜ ìˆë‹¤.",
    "ê¸°ì—…ê³¼ ì§€ìì²´ê°€ ê³µë™ìœ¼ë¡œ ê²°ì •í•œ í”„ë¡œì íŠ¸ëŠ” ë” ë†’ì€ ì‹ ë¢°ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.",
    "ë²•ì  ìš”ê±´ì„ ì¶©ì¡±í•˜ë”ë¼ë„ ì‹œë¯¼ ì‹ ë¢°ë¥¼ í™•ë³´í•˜ë ¤ë©´ ì¶”ê°€ì ì¸ ì„¤ëª…ì´ í•„ìš”í•  ìˆ˜ ìˆë‹¤.",
    "ì§€ì—­ ì–¸ë¡ ì´ ì‹ ì†í•˜ê³  ì •í™•í•˜ê²Œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ë©´ ì‹ ë¢°ì„± ì œê³ ì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤.",
    "ë°ì´í„°ì„¼í„° ì™„ê³µ ì´í›„ì—ë„ ëª¨ë‹ˆí„°ë§ê³¼ í”¼ë“œë°± ì²´ê³„ê°€ ì§€ì†ë˜ë©´ ì‹ ë¢° ìœ ì§€ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤."
]

section_map = {
    "Technology": range(0, 6),
    "People": range(6, 12),
    "Place": range(12, 18),
    "Process": range(18, 24)
}

scale_map = {
    "ì „í˜€ ë™ì˜í•˜ì§€ ì•ŠìŒ": 1,
    "ë™ì˜í•˜ì§€ ì•ŠìŒ": 2,
    "ë³´í†µì´ë‹¤": 3,
    "ë™ì˜í•¨": 4,
    "ë§¤ìš° ë™ì˜í•¨": 5
}
scale_labels = list(scale_map.keys())

# ---------------------------------
# GitHub secrets helper
# ---------------------------------
def _get_secret(path, default=""):
    try:
        cur = st.secrets
        for key in path.split("."):
            cur = cur[key]
        return cur
    except Exception:
        return default

GH_TOKEN   = _get_secret("github.token")
GH_REPO    = _get_secret("github.repo")
GH_BRANCH  = _get_secret("github.branch", "main")
GH_REMOTEP = _get_secret("github.data_path", DATA_PATH)
GH_README  = _get_secret("github.readme_path", "README.md")

# ---------------------------------
# (ì„ íƒ) REST API ë°©ì‹ GitHub ì—…ë¡œë“œ ìœ í‹¸
# ---------------------------------
def _gh_headers(token):
    return {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
        "Content-Type": "application/json",
        "User-Agent": "streamlit-qmethod-sns"
    }

def gh_get_sha(owner_repo, path, token, branch):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    r = requests.get(url, headers=_gh_headers(token), params={"ref": branch}, timeout=20)
    if r.status_code == 200:
        try:
            return r.json().get("sha")
        except Exception:
            return None
    elif r.status_code == 404:
        return None
    else:
        raise RuntimeError(f"GitHub GET ì‹¤íŒ¨: {r.status_code} {r.text}")

def gh_put_file(owner_repo, path, token, branch, content_bytes, message):
    url = f"https://api.github.com/repos/{owner_repo}/contents/{path}"
    b64 = base64.b64encode(content_bytes).decode("ascii")
    sha = gh_get_sha(owner_repo, path, token, branch)
    payload = {"message": message, "content": b64, "branch": branch}
    if sha:
        payload["sha"] = sha
    r = requests.put(url, headers=_gh_headers(token), data=json.dumps(payload), timeout=30)
    if r.status_code in (200, 201):
        return True, r.json()
    return False, f"{r.status_code}: {r.text}"

def push_csv_to_github_rest(local_path, remote_path=None, note="Update survey_data.csv"):
    if not (GH_TOKEN and GH_REPO):
        return False, "GitHub secrets ëˆ„ë½(github.token, github.repo)"
    if remote_path is None:
        remote_path = GH_REMOTEP
    try:
        with open(local_path, "rb") as f:
            content = f.read()
    except Exception as e:
        return False, f"ë¡œì»¬ CSV ì½ê¸° ì‹¤íŒ¨: {e}"
    ok, resp = gh_put_file(GH_REPO, remote_path, GH_TOKEN, GH_BRANCH, content, note)
    return ok, resp

# ---------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (answers / auth / auto_sync)
# ---------------------------------
if "answers" not in st.session_state:
    # ê¸°ë³¸ê°’: ëª¨ë‘ ë³´í†µ(3ì )ìœ¼ë¡œ ì´ˆê¸°í™”
    st.session_state["answers"] = {
        f"Q{i:02}": 3 for i in range(1, len(statements) + 1)
    }

if "authenticated" not in st.session_state:
    st.session_state["authenticated"] = False

if "auto_sync" not in st.session_state:
    st.session_state["auto_sync"] = True

# ---------------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ---------------------------------
def calc_scale_counts(answers: dict):
    counts = {i: 0 for i in range(1, 6)}
    for v in answers.values():
        if v in counts:
            counts[v] += 1
    return counts

def is_valid_email(s: str) -> bool:
    if not s:
        return False
    s = s.strip()
    if len(s) > 150:
        return False
    return bool(EMAIL_RE.match(s))

def load_csv_safe(path: str):
    if not os.path.exists(path):
        return None
    try:
        if os.path.getsize(path) == 0:
            return None
        df = pd.read_csv(path)
        if df.empty:
            return None
        return df
    except Exception:
        return None

def save_csv_safe(df: pd.DataFrame, path: str):
    try:
        df.to_csv(path, index=False, encoding="utf-8-sig")
        return True
    except Exception as e:
        st.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def ensure_q_columns(df: pd.DataFrame, q_count: int):
    cols = [f"Q{i:02d}" for i in range(1, q_count + 1)]
    for c in cols:
        if c not in df.columns:
            df[c] = np.nan
    return df, cols

def zscore_rows(a: np.ndarray):
    m = a.mean(axis=1, keepdims=True)
    s = a.std(axis=1, ddof=0, keepdims=True)
    s = np.where(s < EPS, 1.0, s)
    return (a - m) / s

def rank_rows(a: np.ndarray):
    df = pd.DataFrame(a)
    return df.rank(axis=1, method="average", na_option="keep").values

def varimax(Phi, gamma=1.0, q=100, tol=1e-6, seed=42):
    Phi = Phi.copy()
    p, k = Phi.shape
    R = np.eye(k)
    d_old = 0
    for _ in range(q):
        Lambda = Phi @ R
        u, s, vh = np.linalg.svd(
            Phi.T @ (Lambda**3 - (gamma/p) * (Lambda @ np.diag(np.sum(Lambda**2, axis=0))))
        )
        R = u @ vh
        d = np.sum(s)
        if d_old != 0 and d / d_old < 1 + tol:
            break
        d_old = d
    return Phi @ R, R

def choose_n_factors(eigvals, nmax):
    k = int(np.sum(eigvals >= 1.0))
    return max(2, min(nmax, k))

def get_korean_fontprop():
    font_path = "fonts/NanumGothic.ttf"
    if os.path.exists(font_path):
        return fm.FontProperties(fname=font_path)
    else:
        return fm.FontProperties()  # fallback

font_prop = get_korean_fontprop()

def push_to_github(local_file_path):
    """PyGithub ê¸°ë°˜ CSV í‘¸ì‹œ"""
    try:
        g = Github(st.secrets["github"]["token"])
        repo = g.get_repo(st.secrets["github"]["repo"])
        path_in_repo = st.secrets["github"]["path"]

        with open(local_file_path, "rb") as file:
            content = file.read()

        try:
            contents = repo.get_contents(path_in_repo)
            repo.update_file(
                path=path_in_repo,
                message=f"Update response.csv at {datetime.datetime.now().isoformat()}",
                content=content,
                sha=contents.sha
            )
        except Exception:
            repo.create_file(
                path=path_in_repo,
                message=f"Create response.csv at {datetime.datetime.now().isoformat()}",
                content=content
            )
        return True
    except Exception as e:
        st.error(f"GitHub ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

# ---------------------------------
# ì‚¬ì´ë“œë°” (ê´€ë¦¬ì ë¡œê·¸ì¸ + ì‹¤ì‹œê°„ ì²™ë„ í˜„í™©)
# ---------------------------------
with st.sidebar:
    st.subheader("ğŸ” ê´€ë¦¬ì / ë™ê¸°í™”")

    pw_input = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ (ì„ íƒ)", type="password")
    if st.button("ë¡œê·¸ì¸"):
        if pw_input and _get_secret("admin.password") == pw_input:
            st.session_state["authenticated"] = True
            st.success("ì¸ì¦ ì„±ê³µ")
        else:
            st.error("ì¸ì¦ ì‹¤íŒ¨")

    auto_sync = st.checkbox(
        "ì‘ë‹µ ì €ì¥ ì‹œ GitHub ìë™ í‘¸ì‹œ",
        value=st.session_state.get("auto_sync", True)
    )
    st.session_state["auto_sync"] = auto_sync

    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ì²™ë„ í˜„í™©")

    counts_sidebar = calc_scale_counts(st.session_state["answers"])

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()

    df_counts = pd.DataFrame({
        "ì²™ë„": LIKERT,
        "ì„ íƒ ë¬¸í•­ ìˆ˜": [counts_sidebar[i] for i in range(1, 6)],
        "ìµœëŒ€ í—ˆìš© ê°œìˆ˜": [MAX_COUNT[i] for i in range(1, 6)],
    })
    st.dataframe(df_counts, use_container_width=True)

    fig = go.Figure(data=[
        go.Bar(name="ì„ íƒ ë¬¸í•­ ìˆ˜", x=LIKERT, y=[counts_sidebar[i] for i in range(1, 6)]),
        go.Bar(name="ìµœëŒ€ í—ˆìš© ê°œìˆ˜", x=LIKERT, y=[MAX_COUNT[i] for i in range(1, 6)])
    ])
    fig.update_layout(
        barmode='group',
        yaxis_title="ë¬¸í•­ ìˆ˜",
        xaxis_tickangle=-20,
        template="plotly_white",
        height=350,
        margin=dict(l=10, r=10, t=30, b=10)
    )
    st.plotly_chart(fig, use_container_width=True)

    # ê´€ë¦¬ì ëª¨ë“œì—ì„œ ì‘ë‹µ CSV ë‹¤ìš´ë¡œë“œ
    if st.session_state["authenticated"]:
        st.success("ê´€ë¦¬ì ëª¨ë“œ í™œì„±í™”ë¨")
        if os.path.exists(DATA_PATH):
            try:
                df_download = pd.read_csv(DATA_PATH)
                st.download_button(
                    label="ğŸ“¥ ì‘ë‹µ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
                    data=df_download.to_csv(index=False).encode("utf-8-sig"),
                    file_name="responses.csv",
                    mime="text/csv"
                )
            except pd.errors.EmptyDataError:
                st.warning("âš ï¸ ì €ì¥ëœ ì‘ë‹µ íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.info("â„¹ï¸ ì•„ì§ ì €ì¥ëœ ì‘ë‹µ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------------------
# ë³¸ë¬¸: ì•ˆë‚´ ì„¹ì…˜
# ---------------------------------
with st.expander("ğŸ“˜ ì¡°ì‚¬ ê°œìš”", expanded=True):
    st.markdown("""
    ë³¸ ì¡°ì‚¬ëŠ” ë°ì´í„°ì„¼í„°ì˜ ê¸°ìˆ Â·ì…ì§€Â·ì‚¬ëŒÂ·ê±°ë²„ë„ŒìŠ¤ì— ëŒ€í•œ ì‚¬íšŒì  ìˆ˜ìš©ì„±ê³¼ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ì§„ìˆ ë¬¸ì— ëŒ€í•´, ê·€í•˜ì˜ ì¸ì‹ì„ íŒŒì•…í•˜ê³ ì í•©ë‹ˆë‹¤.<br>
    í•œêµ­ê³µí•™ëŒ€í•™êµ ì£¼ê´€ í•™ìˆ  ì—°êµ¬ ëª©ì ìœ¼ë¡œ ìˆ˜í–‰ë˜ëŠ” ë³¸ ì¡°ì‚¬ëŠ” ì¡°ì‚¬ì§€ ìì²´ì˜ ìµëª…ì„±ì´ ìœ ì§€ë˜ë©° ì‘ë‹µì ê³ ìœ ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì´ë©”ì¼ì„ ìˆ˜ì§‘ í›„ íŒŒê¸°í•©ë‹ˆë‹¤.<br>
    ëª¨ë“  ì„¹ì…˜ì— ì°¸ì—¬í•˜ì‹œëŠ” ë° 10ë¶„ ì´ë‚´ë¡œ ì†Œìš”ë©ë‹ˆë‹¤.<br>
    <br>
    ë°ì´í„°ì„¼í„°ëŠ” ì¸ê³µì§€ëŠ¥, í´ë¼ìš°ë“œ, ë””ì§€í„¸ ì‚°ì—… ë°œì „ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ ê¸°ë°˜ ì‹œì„¤ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·¸ì™€ ë™ì‹œì— ë§‰ëŒ€í•œ ì „ë ¥ì„ ì†Œë¹„í•˜ê³ , ë¬¼ì„ ë§ì´ ì‚¬ìš©í•˜ë©°, ì…ì§€ ì„ ì • ê³¼ì •ì—ì„œ ì‹œë¯¼ë“¤ê³¼ ê°ˆë“±ì„ ë¹šê¸°ë„ í•©ë‹ˆë‹¤.<br>
    <br>
    ë™ ì—°êµ¬ì—ì„œëŠ”<br>
    - ì‹œë¯¼ë“¤ì€ ë°ì´í„°ì„¼í„°ì— ëŒ€í•´ ì–´ë–¤ ìƒê°ì„ ê°€ì§€ê³  ìˆì„ê¹Œ?<br>
    - ê·¸ë¦¬ê³  ê·¸ íŒë‹¨ì€ ì–´ë–¤ ê°€ì¹˜ë‚˜ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë‹¬ë¼ì§ˆê¹Œ?<br>
    ë¥¼ ì•Œì•„ë³´ê¸° ìœ„í•œ ëª©ì ì„ ê°€ì§€ê³  ì„¤ë¬¸ì¡°ì‚¬ë¥¼ ì‹œí–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.<br><br>
    ì„¤ë¬¸ì€ ì´ 24ê°œì˜ ë¬¸ì¥ì„ ì œì‹œí•˜ë©°, ì´ ë¬¸ì¥ë“¤ì€ ì‚¬ëŒë“¤ì´ ë°ì´í„°ì„¼í„°ì— ëŒ€í•´ í”íˆ í•˜ëŠ” ì£¼ì¥ì´ë‚˜ ì˜ê²¬ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.
    """, unsafe_allow_html=True)

with st.expander("ğŸ§© ì„¹ì…˜ ì„¤ëª…", expanded=True):
    st.markdown("""
    ì„¤ë¬¸ì€ ë¦¬ì»¤íŠ¸ ë°©ì‹ìœ¼ë¡œ ì§„í–‰ë˜ë©°, ì œì‹œëœ 24ê°œ ë¬¸ì¥ì„ â€œë‚˜ëŠ” ì´ ìƒê°ì— ì–¼ë§ˆë‚˜ ë™ì˜í•˜ëŠ”ê°€?â€ì˜ ê¸°ì¤€ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.<br>
    <b>ë§¤ìš° ë™ì˜í•˜ê±°ë‚˜ ë™ì˜í•˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ì´ 1-3ë¬¸ì¥ ì´ë‚´ë¡œ í•˜ì‹œê³ , ê¸°ë³¸ì ìœ¼ë¡œ ì¤‘ë¦½ì ì´ê±°ë‚˜ íŒë‹¨ì„ ìœ ë³´í•˜ì‹œê³  ì‹¶ì€ ë¬¸ì¥ì€ ì£¼ë¡œ ë³´í†µì´ë‹¤ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.</b><br>
    ë¬¸ì¥ë“¤ì€ ë‹¤ìŒ ë„¤ ê°œì˜ ê´€ì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:<br>
      1) ê¸°ìˆ (Technology)<br>
      2) ì‚¬ëŒ(People)<br>
      3) ì¥ì†Œ(Place)<br>
      4) ê³¼ì •(Process)<br>
    """, unsafe_allow_html=True)

# ---------------------------------
# íƒ­ êµ¬ì„±
# ---------------------------------
tab1, tab2, tab3 = st.tabs(["âœï¸ ì„¤ë¬¸ ì‘ë‹µ", "ğŸ“Š", "ğŸ§ "])

# ---------------------------------
# Tab 1: ì„¤ë¬¸ ì‘ë‹µ
# ---------------------------------
with tab1:
    st.subheader("âœï¸ ì„¤ë¬¸ì— ì‘ë‹µí•´ ì£¼ì„¸ìš”")

    # ì´ë©”ì¼ ì…ë ¥
    email = st.text_input("ì´ë©”ì¼ì„ ì…ë ¥í•´ ì£¼ì„¸ìš” (í•„ìˆ˜ ì‚¬í•­)", key="email_input")

    # ==========================================
    # [ì¶”ê°€ë¨] ì‚¬ìš©ì ì¸ì ì‚¬í•­ ì…ë ¥ í•„ë“œ
    # ==========================================
    col1, col2 = st.columns(2)
    with col1:
        expertise = st.selectbox(
            "1) ë‚˜ëŠ” ë‹¤ìŒ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì´ë‹¤",
            ["ì „ë ¥ë§ ì¸í”„ë¼", "ë°ì´í„°ì„¼í„° ìš´ì˜", "í”Œë«í¼ êµ¬ì¶•"],
            key="expertise_input"
        )
    with col2:
        experience_years = st.number_input(
            "2) ê²½ë ¥ë…„ìˆ˜ (ë…„)",
            min_value=0, max_value=60, step=1, value=0,
            key="experience_input"
        )
    
    affiliation = st.selectbox(
        "3) ì†Œì† ìœ í˜•",
        ["í•™ê³„", "ì‚°ì—…ê³„", "í˜‘íšŒ/ì¶œì—°ì—°/ê³µê³µê¸°ê´€"],
        key="affiliation_input"
    )
    st.markdown("---") # êµ¬ë¶„ì„  ì¶”ê°€
    # ==========================================

    # ë¬¸í•­ë³„ ë¼ë””ì˜¤ ë²„íŠ¼ â€“ ì„ íƒ ì‹œ ë°”ë¡œ session_state["answers"] ë°˜ì˜
    for idx, stmt in enumerate(statements, 1):
        q_key = f"Q{idx:02}"

        current_val = st.session_state["answers"].get(q_key, 3)
        current_label = [k for k, v in scale_map.items() if v == current_val][0]
        default_index = scale_labels.index(current_label)

        selected_label = st.radio(
            f"{idx}. {stmt}",
            options=scale_labels,
            index=default_index,
            key=q_key,
            horizontal=True
        )

        st.session_state["answers"][q_key] = scale_map[selected_label]

    # ì œì¶œ ë²„íŠ¼ â€“ í˜„ì¬ session_state["answers"]ë¥¼ ê·¸ëŒ€ë¡œ ì €ì¥
    if st.button("ì œì¶œí•˜ê¸°"):
        # 1) ì´ë©”ì¼ ê²€ì¦
        if not is_valid_email(email):
            st.error("ì˜¬ë°”ë¥¸ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            # 2) ì‘ë‹µ ë¶„í¬ ê²€ì¦ (MAX_COUNT ì´ˆê³¼ ì—¬ë¶€ ì²´í¬)
            counts_current = calc_scale_counts(st.session_state["answers"])
            over = {
                i: counts_current[i]
                for i in counts_current
                if counts_current[i] > MAX_COUNT[i]
            }

            if over:
                # ì´ˆê³¼ëœ ì²™ë„ë³„ë¡œ ìƒì„¸ ë©”ì‹œì§€
                lines = []
                for i, cnt in over.items():
                    lines.append(
                        f"- '{LIKERT[i-1]}' ì„ íƒ ë¬¸í•­ ìˆ˜: {cnt}ê°œ (í—ˆìš© {MAX_COUNT[i]}ê°œ ì´ë‚´)"
                    )
                st.error(
                    "ì‘ë‹µ ë¶„í¬ê°€ í—ˆìš© ê°œìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. "
                    "ì‚¬ì´ë“œë°”ì˜ 'ìµœëŒ€ í—ˆìš© ê°œìˆ˜'ë¥¼ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì²™ë„ì˜ ê°œìˆ˜ë¥¼ ì¡°ì •í•´ ì£¼ì„¸ìš”.\n\n"
                    + "\n".join(lines)
                )
            else:
                # 3) ë¶„í¬ê°€ í—ˆìš© ë²”ìœ„ ì´ë‚´ì´ë©´ ì €ì¥
                responses = dict(st.session_state["answers"])
                responses["email"] = email.strip()
                
                # [ì¶”ê°€ë¨] ì¶”ê°€ ì…ë ¥ í•„ë“œ ë°ì´í„° ì €ì¥
                responses["expertise"] = expertise
                responses["experience_years"] = experience_years
                responses["affiliation"] = affiliation

                df_new = pd.DataFrame([responses])
                if os.path.exists(DATA_PATH):
                    df_old = pd.read_csv(DATA_PATH)
                    df_all = pd.concat([df_old, df_new], ignore_index=True)
                else:
                    df_all = df_new

                if save_csv_safe(df_all, DATA_PATH):
                    st.success("ì‘ë‹µì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    if st.session_state.get("auto_sync", True):
                        push_to_github(DATA_PATH)

# ---------------------------------
# Tab 2: ìœ í˜• ë¶„ì„ / TPPP í”„ë¡œíŒŒì¼ë§
# ---------------------------------
with tab2:
    if os.path.exists(DATA_PATH):
        df = pd.read_csv(DATA_PATH)
        st.subheader("ğŸ“ˆ ìœ í˜• ë¶„ì„ ë° TPPP ì˜ì—­ë³„ í”„ë¡œíŒŒì¼ë§")
        if len(df) >= 5:
            df_numeric = df.select_dtypes(include=[np.number])
            # Drop extra numeric columns if they exist (like experience_years) to avoid factor analysis error
            # ë¬¸í•­(Q01~Q24)ë§Œ ì„ íƒí•˜ë„ë¡ í•„í„°ë§
            q_cols = [c for c in df_numeric.columns if c.startswith("Q")]
            df_numeric_q = df_numeric[q_cols]

            noise = np.random.normal(0, 0.001, df_numeric_q.shape)
            df_noise = df_numeric_q + noise
            df_noise_numeric = df_noise.apply(pd.to_numeric, errors='coerce')
            df_noise_numeric = df_noise_numeric.dropna()
            df_noise_numeric = df_noise.select_dtypes(include=[np.number])

            fa_temp = FactorAnalyzer(rotation=None)
            
            fa_temp.fit(df_noise)
            eigen_values, _ = fa_temp.get_eigenvalues()
            n_factors = sum(eigen_values >= 1.0)

            st.info(f"ğŸ” ê³ ìœ ê°’ 1.0 ì´ìƒ ê¸°ì¤€, ì¶”ì¶œëœ ìš”ì¸ ìˆ˜: {n_factors}ê°œ")

            fa = FactorAnalyzer(n_factors=n_factors, rotation='varimax')
            fa.fit(df_noise)

            loadings = pd.DataFrame(
                fa.loadings_,
                index=[f"Q{idx+1:02d}" for idx in range(df_numeric_q.shape[1])],
                columns=[f"Type{i+1}" for i in range(n_factors)]
            )

            st.write("ğŸ“Œ ìœ í˜• ë¶€í•˜ í–‰ë ¬:")
            st.dataframe(loadings)

            st.write("ğŸ“Š ìœ í˜•ë³„ TPPP í‰ê·  í”„ë¡œíŒŒì¼")
            result = []
            for factor in loadings.columns:
                scores = []
                for sec, idxs in section_map.items():
                    mean = loadings.loc[[f"Q{i+1:02d}" for i in idxs], factor].mean()
                    scores.append((sec, mean))
                row = pd.DataFrame(dict(scores), index=[factor])
                result.append(row)
            summary = pd.concat(result)
            st.dataframe(summary.style.background_gradient(axis=1, cmap='Blues'))

            fig, ax = plt.subplots()
            summary.T.plot(kind='bar', ax=ax)
            ax.set_title("ìœ í˜•ë³„ TPPP ì˜ì—­ ì ìˆ˜", fontproperties=font_prop)
            st.pyplot(fig)
        else:
            st.warning("ìµœì†Œ 5ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ---------------------------------
# Tab 3: TPPP ì¸ì§€ íë¦„ / í”¼ë“œë°± êµ¬ì¡°
# ---------------------------------
with tab3:
    if os.path.exists(DATA_PATH):
        df = pd.read_csv(DATA_PATH)
        st.subheader("ğŸ§  TPPP ì¸ì§€ íë¦„ ë° í”¼ë“œë°± êµ¬ì¡° ìš”ì•½")

        if len(df) >= 5:
            df_numeric = df.select_dtypes(include=[np.number])
            # ë¬¸í•­(Q01~Q24)ë§Œ ì„ íƒ
            q_cols = [c for c in df_numeric.columns if c.startswith("Q")]
            df_numeric_q = df_numeric[q_cols]

            noise = np.random.normal(0, 0.001, df_numeric_q.shape)
            df_n = df_numeric_q + noise

            corr = df_n.corr()
            tp_labels = list(section_map.keys())
            block_corr = pd.DataFrame(index=tp_labels, columns=tp_labels, dtype=float)

            for sec1, idxs1 in section_map.items():
                for sec2, idxs2 in section_map.items():
                    sub_corrs = [corr.iloc[i, j] for i in idxs1 for j in idxs2 if i != j]
                    block_corr.loc[sec1, sec2] = np.mean(sub_corrs)

            DG = nx.DiGraph()
            for i in tp_labels:
                DG.add_node(i)

            for i in tp_labels:
                for j in tp_labels:
                    if i != j:
                        weight_ij = block_corr.loc[i, j]
                        weight_ji = block_corr.loc[j, i]
                        if weight_ij > weight_ji and weight_ij > 0.4:
                            DG.add_edge(i, j, weight=round(weight_ij, 2))

            st.markdown("### ğŸ”„ TPPP ì¸ì§€ íë¦„ ë°©í–¥ ê·¸ë˜í”„ (DiGraph)")
            pos = nx.circular_layout(DG)
            plt.figure(figsize=(6, 6))
            nx.draw_networkx_nodes(DG, pos, node_color='skyblue', node_size=2000)
            nx.draw_networkx_labels(DG, pos, font_size=12, font_family=font_prop.get_name())
            nx.draw_networkx_edges(DG, pos, width=2, arrows=True, arrowstyle='-|>')
            edge_labels = {(u, v): f"{d['weight']}" for u, v, d in DG.edges(data=True)}
            nx.draw_networkx_edge_labels(
                DG, pos, edge_labels=edge_labels,
                font_size=10, font_family=font_prop.get_name()
            )
            plt.title("TPPP ì˜ì—­ ê°„ ì¸ì§€ íë¦„ êµ¬ì¡° (DiGraph)", fontproperties=font_prop)
            st.pyplot(plt)

            st.markdown("### ğŸ” í”¼ë“œë°± ë£¨í”„ êµ¬ì¡° ê°ì§€ ê²°ê³¼")
            cycles = [cycle for cycle in nx.simple_cycles(DG) if len(cycle) >= 3]

            if cycles:
                for i, loop in enumerate(cycles, 1):
                    st.markdown(f"- ë£¨í”„ {i}: {' â†’ '.join(loop)} â†’ {loop[0]}")
            else:
                st.info("ë£¨í”„(ìê¸°ê°•í™” í”¼ë“œë°± êµ¬ì¡°)ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            st.markdown("### ğŸ“Š TPPP ìƒê´€ í–‰ë ¬ íˆíŠ¸ë§µ")
            fig2, ax2 = plt.subplots()
            sns.heatmap(
                block_corr.astype(float),
                annot=True,
                cmap='coolwarm',
                vmin=-1, vmax=1,
                fmt=".2f",
                linewidths=0.5,
                ax=ax2,
                cbar=True
            )
            ax2.set_title("TPPP ë¸”ë¡ ê°„ ìƒê´€ íˆíŠ¸ë§µ", fontproperties=font_prop)
            ax2.set_xticklabels(ax2.get_xticklabels(), fontproperties=font_prop)
            ax2.set_yticklabels(ax2.get_yticklabels(), fontproperties=font_prop)
            st.pyplot(fig2)
        else:
            st.warning("ìµœì†Œ 5ëª…ì˜ ì‘ë‹µì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        st.info("ì‘ë‹µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
